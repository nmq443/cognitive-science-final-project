{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8455971,"sourceType":"datasetVersion","datasetId":5039749}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/nmq443/cognitive-science-final-project.git","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:44:59.274837Z","iopub.execute_input":"2024-05-19T09:44:59.275267Z","iopub.status.idle":"2024-05-19T09:45:01.544587Z","shell.execute_reply.started":"2024-05-19T09:44:59.275211Z","shell.execute_reply":"2024-05-19T09:45:01.543226Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Cloning into 'cognitive-science-final-project'...\nremote: Enumerating objects: 169, done.\u001b[K\nremote: Counting objects: 100% (169/169), done.\u001b[K\nremote: Compressing objects: 100% (139/139), done.\u001b[K\nremote: Total 169 (delta 76), reused 88 (delta 26), pack-reused 0\u001b[K\nReceiving objects: 100% (169/169), 4.90 MiB | 6.96 MiB/s, done.\nResolving deltas: 100% (76/76), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nos.chdir('/kaggle/working/cognitive-science-final-project/')","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:45:01.546655Z","iopub.execute_input":"2024-05-19T09:45:01.547042Z","iopub.status.idle":"2024-05-19T09:45:01.553467Z","shell.execute_reply.started":"2024-05-19T09:45:01.547007Z","shell.execute_reply":"2024-05-19T09:45:01.552311Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from train import train_model\nfrom utils import getModel\nfrom evaluation import test\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:46:36.382057Z","iopub.execute_input":"2024-05-19T09:46:36.382514Z","iopub.status.idle":"2024-05-19T09:46:36.389038Z","shell.execute_reply.started":"2024-05-19T09:46:36.382480Z","shell.execute_reply":"2024-05-19T09:46:36.387593Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\ntry:\n  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nexcept ValueError:\n  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_data_path = '/kaggle/input/bci-competition-iv-2a'","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:46:39.944848Z","iopub.execute_input":"2024-05-19T09:46:39.947821Z","iopub.status.idle":"2024-05-19T09:46:39.953920Z","shell.execute_reply.started":"2024-05-19T09:46:39.947776Z","shell.execute_reply":"2024-05-19T09:46:39.952347Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def run():\n    # Define dataset parameters\n    dataset = 'BCI2a' # Options: 'BCI2a','HGD', 'CS2R'\n    \n    if dataset == 'BCI2a': \n        in_samples = 1125\n        n_channels = 22\n        n_sub = 9\n        n_classes = 4\n        classes_labels = ['Left hand', 'Right hand','Foot','Tongue']\n        data_path = os.path.expanduser(root_data_path) + '/BCI Competition IV/BCI Competition IV-2a/BCI Competition IV 2a mat/'\n    elif dataset == 'HGD': \n        in_samples = 1125\n        n_channels = 44\n        n_sub = 14\n        n_classes = 4\n        classes_labels = ['Right Hand', 'Left Hand','Rest','Feet']     \n        data_path = os.path.expanduser(root_data_path) + '/mne_data/MNE-schirrmeister2017-data/robintibor/high-gamma-dataset/raw/master/data/'\n    elif dataset == 'CS2R': \n        in_samples = 1125\n        # in_samples = 576\n        n_channels = 32\n        n_sub = 18\n        n_classes = 3\n        # classes_labels = ['Fingers', 'Wrist','Elbow','Rest']     \n        classes_labels = ['Fingers', 'Wrist','Elbow']     \n        # classes_labels = ['Fingers', 'Elbow']     \n        data_path = os.path.expanduser(root_data_path) + '/CS2R MI EEG dataset/all/EDF - Cleaned - phase one (remove extra runs)/two sessions/'\n    else:\n        raise Exception(\"'{}' dataset is not supported yet!\".format(dataset))\n        \n    # Create a folder to store the results of the experiment\n    results_path = os.getcwd() + \"/results\"\n    if not  os.path.exists(results_path):\n      os.makedirs(results_path)   # Create a new directory if it does not exist \n      \n    # Set dataset paramters \n    dataset_conf = { 'name': dataset, 'n_classes': n_classes, 'cl_labels': classes_labels,\n                    'n_sub': n_sub, 'n_channels': n_channels, 'in_samples': in_samples,\n                    'data_path': data_path, 'isStandard': True, 'LOSO': False}\n    # Set training hyperparamters\n    train_conf = { 'batch_size': 64, 'epochs': 500, 'patience': 100, 'lr': 0.001,'n_train': 1,\n                  'LearnCurves': True, 'from_logits': False, 'model':'ATCNet'}\n           \n    # Train the model\n    train_model(dataset_conf, train_conf, results_path)\n\n    # Evaluate the model based on the weights saved in the '/results' folder\n    model = getModel(train_conf.get('model'), dataset_conf)\n    test(model, dataset_conf, results_path)    \n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:47:08.787128Z","iopub.execute_input":"2024-05-19T09:47:08.788331Z","iopub.status.idle":"2024-05-19T09:47:08.803083Z","shell.execute_reply.started":"2024-05-19T09:47:08.788277Z","shell.execute_reply":"2024-05-19T09:47:08.801649Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"run()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:47:09.765109Z","iopub.execute_input":"2024-05-19T09:47:09.765542Z","iopub.status.idle":"2024-05-19T09:47:13.879816Z","shell.execute_reply.started":"2024-05-19T09:47:09.765510Z","shell.execute_reply":"2024-05-19T09:47:13.878140Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\nTraining on subject  1\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[12], line 46\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m train_conf \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m64\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.001\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_train\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     43\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearnCurves\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom_logits\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATCNet\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Evaluate the model based on the weights saved in the '/results' folder\u001b[39;00m\n\u001b[1;32m     49\u001b[0m model \u001b[38;5;241m=\u001b[39m getModel(train_conf\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m), dataset_conf)\n","File \u001b[0;32m/kaggle/working/cognitive-science-final-project/train.py:95\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(dataset_conf, train_conf, results_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39mfrom_logits), optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])          \n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# model.summary()\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# plot_model(model, to_file='plot_model.png', show_shapes=True, show_layer_names=True)\u001b[39;00m\n\u001b[1;32m     94\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 95\u001b[0m     \u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_weights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     97\u001b[0m     ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),  \n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=patience)\u001b[39;00m\n\u001b[1;32m     99\u001b[0m ]\n\u001b[1;32m    100\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train_onehot, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val_onehot), \n\u001b[1;32m    101\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Evaluate the performance of the trained model based on the validation data\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Here we load the Trained weights from the file saved in the hard \u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# disk, which should be the same as the weights of the current model.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks/model_checkpoint.py:183\u001b[0m, in \u001b[0;36mModelCheckpoint.__init__\u001b[0;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_weights_only:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 183\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `save_weights_only=True` in `ModelCheckpoint`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, the filepath provided must end in `.weights.h5` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Keras weights format). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","\u001b[0;31mValueError\u001b[0m: When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=/kaggle/working/cognitive-science-final-project/results/saved models/run-1/subject-1.h5"],"ename":"ValueError","evalue":"When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=/kaggle/working/cognitive-science-final-project/results/saved models/run-1/subject-1.h5","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}