{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "668e5e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T10:01:52.634608Z",
     "iopub.status.busy": "2024-05-19T10:01:52.633687Z",
     "iopub.status.idle": "2024-05-19T10:01:55.357841Z",
     "shell.execute_reply": "2024-05-19T10:01:55.356456Z",
     "shell.execute_reply.started": "2024-05-19T10:01:52.634571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cognitive-science-final-project'...\n",
      "remote: Enumerating objects: 179, done.\u001b[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
      "remote: Total 179 (delta 0), reused 1 (delta 0), pack-reused 167\u001b[K\n",
      "Receiving objects: 100% (179/179), 4.91 MiB | 10.51 MiB/s, done.\n",
      "Resolving deltas: 100% (80/80), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/nmq443/cognitive-science-final-project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd781ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T10:01:55.361252Z",
     "iopub.status.busy": "2024-05-19T10:01:55.360902Z",
     "iopub.status.idle": "2024-05-19T10:01:55.369239Z",
     "shell.execute_reply": "2024-05-19T10:01:55.366713Z",
     "shell.execute_reply.started": "2024-05-19T10:01:55.361218Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/kaggle/working/cognitive-science-final-project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c197464f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T10:01:55.371409Z",
     "iopub.status.busy": "2024-05-19T10:01:55.370977Z",
     "iopub.status.idle": "2024-05-19T10:02:11.283440Z",
     "shell.execute_reply": "2024-05-19T10:02:11.282419Z",
     "shell.execute_reply.started": "2024-05-19T10:01:55.371369Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 10:01:57.693212: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-19 10:01:57.693315: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-19 10:01:57.853700: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from train import train_model \n",
    "from utils import getModel\n",
    "from evaluation import test\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867c6be6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T10:02:11.286588Z",
     "iopub.status.busy": "2024-05-19T10:02:11.285763Z",
     "iopub.status.idle": "2024-05-19T10:02:12.475623Z",
     "shell.execute_reply": "2024-05-19T10:02:12.473888Z",
     "shell.execute_reply.started": "2024-05-19T10:02:11.286553Z"
    }
   },
   "outputs": [
    {
     "ename": "BaseException",
     "evalue": "ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m   tpu \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_resolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTPUClusterResolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# TPU detection\u001b[39;00m\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning on TPU \u001b[39m\u001b[38;5;124m'\u001b[39m, tpu\u001b[38;5;241m.\u001b[39mcluster_spec()\u001b[38;5;241m.\u001b[39mas_dict()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py:235\u001b[0m, in \u001b[0;36mTPUClusterResolver.__init__\u001b[0;34m(self, tpu, zone, project, job_name, coordinator_name, coordinator_address, credentials, service, discovery_url)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tpu \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    234\u001b[0m   \u001b[38;5;66;03m# Default Cloud environment\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cloud_tpu_client \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m      \u001b[49m\u001b[43mzone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m      \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m      \u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdiscovery_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscovery_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cloud_tpu_client\u001b[38;5;241m.\u001b[39mname()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cloud_tpu_client/client.py:139\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, tpu, zone, project, credentials, service, discovery_url)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tpu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease provide a TPU Name to connect to.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tpu \u001b[38;5;241m=\u001b[39m _as_text(tpu)\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide a TPU Name to connect to.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mBaseException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning on TPU \u001b[39m\u001b[38;5;124m'\u001b[39m, tpu\u001b[38;5;241m.\u001b[39mcluster_spec()\u001b[38;5;241m.\u001b[39mas_dict()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental_connect_to_cluster(tpu)\n\u001b[1;32m     10\u001b[0m tf\u001b[38;5;241m.\u001b[39mtpu\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39minitialize_tpu_system(tpu)\n",
      "\u001b[0;31mBaseException\u001b[0m: ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d13b244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T10:02:16.279251Z",
     "iopub.status.busy": "2024-05-19T10:02:16.278287Z",
     "iopub.status.idle": "2024-05-19T10:02:16.285029Z",
     "shell.execute_reply": "2024-05-19T10:02:16.284028Z",
     "shell.execute_reply.started": "2024-05-19T10:02:16.279205Z"
    }
   },
   "outputs": [],
   "source": [
    "# if run on colab\n",
    "# root_data_path = 'content/drive/...'\n",
    "# if run on local machine\n",
    "# root_data_path = '~'\n",
    "root_data_path = '/kaggle/input/bci-competition-iv-2a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e9a1d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T10:02:17.024710Z",
     "iopub.status.busy": "2024-05-19T10:02:17.022942Z",
     "iopub.status.idle": "2024-05-19T10:02:17.037269Z",
     "shell.execute_reply": "2024-05-19T10:02:17.035932Z",
     "shell.execute_reply.started": "2024-05-19T10:02:17.024666Z"
    }
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    # Define dataset parameters\n",
    "    dataset = 'BCI2a' # Options: 'BCI2a','HGD', 'CS2R'\n",
    "    \n",
    "    if dataset == 'BCI2a': \n",
    "        in_samples = 1125\n",
    "        n_channels = 22\n",
    "        n_sub = 9\n",
    "        n_classes = 4\n",
    "        classes_labels = ['Left hand', 'Right hand','Foot','Tongue']\n",
    "        data_path = os.path.expanduser(root_data_path) + '/BCI Competition IV/BCI Competition IV-2a/BCI Competition IV 2a mat/'\n",
    "    elif dataset == 'HGD': \n",
    "        in_samples = 1125\n",
    "        n_channels = 44\n",
    "        n_sub = 14\n",
    "        n_classes = 4\n",
    "        classes_labels = ['Right Hand', 'Left Hand','Rest','Feet']     \n",
    "        data_path = os.path.expanduser(root_data_path) + '/mne_data/MNE-schirrmeister2017-data/robintibor/high-gamma-dataset/raw/master/data/'\n",
    "    elif dataset == 'CS2R': \n",
    "        in_samples = 1125\n",
    "        # in_samples = 576\n",
    "        n_channels = 32\n",
    "        n_sub = 18\n",
    "        n_classes = 3\n",
    "        # classes_labels = ['Fingers', 'Wrist','Elbow','Rest']     \n",
    "        classes_labels = ['Fingers', 'Wrist','Elbow']     \n",
    "        # classes_labels = ['Fingers', 'Elbow']     \n",
    "        data_path = os.path.expanduser(root_data_path) + '/CS2R MI EEG dataset/all/EDF - Cleaned - phase one (remove extra runs)/two sessions/'\n",
    "    else:\n",
    "        raise Exception(\"'{}' dataset is not supported yet!\".format(dataset))\n",
    "        \n",
    "    # Create a folder to store the results of the experiment\n",
    "    results_path = os.getcwd() + \"/results\"\n",
    "    if not  os.path.exists(results_path):\n",
    "      os.makedirs(results_path)   # Create a new directory if it does not exist \n",
    "      \n",
    "    # Set dataset paramters \n",
    "    dataset_conf = { 'name': dataset, 'n_classes': n_classes, 'cl_labels': classes_labels,\n",
    "                    'n_sub': n_sub, 'n_channels': n_channels, 'in_samples': in_samples,\n",
    "                    'data_path': data_path, 'isStandard': True, 'LOSO': False}\n",
    "    # Set training hyperparamters\n",
    "    train_conf = { 'batch_size': 64, 'epochs': 500, 'patience': 100, 'lr': 0.001,'n_train': 1,\n",
    "                  'LearnCurves': True, 'from_logits': False, 'model':'ATCNet'}\n",
    "           \n",
    "    # Train the model\n",
    "    train_model(dataset_conf, train_conf, results_path)\n",
    "\n",
    "    # Evaluate the model based on the weights saved in the '/results' folder\n",
    "    model = getModel(train_conf.get('model'), dataset_conf)\n",
    "    test(model, dataset_conf, results_path)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4154ca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T10:02:17.541216Z",
     "iopub.status.busy": "2024-05-19T10:02:17.540812Z",
     "iopub.status.idle": "2024-05-19T10:02:32.745147Z",
     "shell.execute_reply": "2024-05-19T10:02:32.743994Z",
     "shell.execute_reply.started": "2024-05-19T10:02:17.541184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.15.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: explainable-ai-sdk, tensorflow-cloud, tensorflow-decision-forests, tensorflow-serving-api, tensorflow-text, tf_keras, witwidget\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf5c279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T10:02:32.748999Z",
     "iopub.status.busy": "2024-05-19T10:02:32.748628Z",
     "iopub.status.idle": "2024-05-19T10:02:36.703022Z",
     "shell.execute_reply": "2024-05-19T10:02:36.701448Z",
     "shell.execute_reply.started": "2024-05-19T10:02:32.748964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on subject  1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=/kaggle/working/cognitive-science-final-project/results/saved models/run-1/subject-1.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m train_conf \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m64\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.001\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_train\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     43\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearnCurves\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom_logits\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATCNet\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Evaluate the model based on the weights saved in the '/results' folder\u001b[39;00m\n\u001b[1;32m     49\u001b[0m model \u001b[38;5;241m=\u001b[39m getModel(train_conf\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m), dataset_conf)\n",
      "File \u001b[0;32m/kaggle/working/cognitive-science-final-project/train.py:95\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(dataset_conf, train_conf, results_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39mfrom_logits), optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])          \n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# model.summary()\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# plot_model(model, to_file='plot_model.png', show_shapes=True, show_layer_names=True)\u001b[39;00m\n\u001b[1;32m     94\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 95\u001b[0m     \u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_weights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     97\u001b[0m     ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),  \n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=patience)\u001b[39;00m\n\u001b[1;32m     99\u001b[0m ]\n\u001b[1;32m    100\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train_onehot, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val_onehot), \n\u001b[1;32m    101\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Evaluate the performance of the trained model based on the validation data\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Here we load the Trained weights from the file saved in the hard \u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# disk, which should be the same as the weights of the current model.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks/model_checkpoint.py:183\u001b[0m, in \u001b[0;36mModelCheckpoint.__init__\u001b[0;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_weights_only:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 183\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `save_weights_only=True` in `ModelCheckpoint`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, the filepath provided must end in `.weights.h5` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Keras weights format). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=/kaggle/working/cognitive-science-final-project/results/saved models/run-1/subject-1.h5"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af1db34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5039749,
     "sourceId": 8455971,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
