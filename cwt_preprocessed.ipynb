{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55c3a28",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nmq443/cognitive-science-final-project/blob/quang-branch/cwt_preprocessed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "j_NbHZzX4lhL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_NbHZzX4lhL",
    "outputId": "b950532e-8cd8-488e-ddd5-f314a0c78692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# If running on colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VtlNf9695qnF",
   "metadata": {
    "id": "VtlNf9695qnF"
   },
   "outputs": [],
   "source": [
    "# !pip install torcheeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sTs2JbN24z-1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTs2JbN24z-1",
    "outputId": "d5bc337e-2876-4a30-dd59-62b9cee62a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cognitive-science-final-project'...\n",
      "remote: Enumerating objects: 219, done.\u001b[K\n",
      "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
      "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
      "remote: Total 219 (delta 18), reused 22 (delta 5), pack-reused 167\u001b[K\n",
      "Receiving objects: 100% (219/219), 5.59 MiB | 13.19 MiB/s, done.\n",
      "Resolving deltas: 100% (98/98), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/nmq443/cognitive-science-final-project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "T88-R16Q4322",
   "metadata": {
    "id": "T88-R16Q4322"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/content/cognitive-science-final-project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e6745-2dd8-495c-99e7-fc0e90892825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg.transforms import CWTSpectrum\n",
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(288, 1, 22, 1125)\n",
    "t = CWTSpectrum(contourf=True)\n",
    "\n",
    "num_trials, num_inputs, num_eegs, num_samples = X.shape\n",
    "\n",
    "fs = 250\n",
    "freq_range = (1, 15)\n",
    "freq_bins = 100\n",
    "w = 5\n",
    "freq = np.linspace(freq_range[0],freq_range[1],freq_bins)\n",
    "widths = w * fs / (2 * freq * np.pi)\n",
    "\n",
    "X_cwt = np.zeros((num_trials, num_eegs, widths.shape[0], num_samples))\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    for in_ in range(num_inputs):\n",
    "        X_cwt.append(t(eeg=X[trial, in_, :, :])['eeg'])\n",
    "\n",
    "print(len(X_cwt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8156645-7397-4ffd-99fb-87751b49df8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "1\n",
      "22\n",
      "1125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(288, 1, 22, 1125)\n",
    "num_trials, num_inputs, num_eegs, num_samples = X.shape\n",
    "print(num_trials)\n",
    "print(num_inputs)\n",
    "print(num_eegs)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b6aeaa-fd93-4b5e-935e-9d1f504be891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "fs = 250\n",
    "freq_range = (1, 15)\n",
    "freq_bins = 100\n",
    "w = 5\n",
    "freq = np.linspace(freq_range[0],freq_range[1],freq_bins)\n",
    "widths = w * fs / (2 * freq * np.pi)\n",
    "print(widths.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7dc440-3606-4833-9784-2e0334c38c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n",
      "(22, 128, 1125)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torcheeg.transforms import CWTSpectrum\n",
    "\n",
    "t = CWTSpectrum()\n",
    "\n",
    "# X_cwt = np.zeros((num_trials, widths.shape[0], num_eegs, num_samples))\n",
    "\n",
    "X_cwt = []\n",
    "for trial in range(num_trials):\n",
    "    for in_ in range(num_inputs):\n",
    "        transformed = t(eeg=X[trial, in_, :, :])['eeg']\n",
    "        print(transformed.shape)\n",
    "        X_cwt.append(transformed)\n",
    "\n",
    "print(X_cwt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0c28fc-7871-44c5-afac-40ac3e7b4510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 100, 22, 1125)\n"
     ]
    }
   ],
   "source": [
    "X_cwt = np.zeros((num_trials, widths.shape[0], num_eegs, num_samples))\n",
    "print(X_cwt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee09e2b2-8d07-4613-8c2b-e7d311b06bf6",
   "metadata": {
    "id": "ee09e2b2-8d07-4613-8c2b-e7d311b06bf6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "def morlet_wavelet_transform(X,fs=250,freq_range=(1,15),freq_bins=100,w=5):\n",
    "    '''\n",
    "    Discrete continous wavelet transform of eeg data convolved with complex morlet wavelet\n",
    "    INPUTS:\n",
    "    X - EEG data (num_trials, 1, num_eeg_electrodes, time_bins)\n",
    "    fs - sampling rate in Hz\n",
    "    freq_range - tuple containing min and max freq range to perform analysis within\n",
    "    freq_bins - number of points between freq range being analyzed\n",
    "    w - Omega0 for complex morlet wavelet\n",
    "    OUTPUTS:\n",
    "    X_cwt - Wavlet transformed eeg data (num_trials, num_eeg_electrodes,freq_bins,time_bins)\n",
    "    '''\n",
    "\n",
    "    N_trials, _, N_eegs, time_bins = X.shape\n",
    "    # values for cwt\n",
    "    freq = np.linspace(freq_range[0],freq_range[1],freq_bins)\n",
    "    widths = w * fs / (2 * freq * np.pi)\n",
    "    X_cwt = np.zeros((N_trials,widths.shape[0],N_eegs,time_bins))\n",
    "\n",
    "    print('Performing discrete CWT convolutions...')\n",
    "    for trial in range(N_trials):\n",
    "        for eeg in range(N_eegs):\n",
    "            X_cwt[trial,:,eeg,:] = np.abs(signal.cwt(np.squeeze(X[trial,:,eeg,]),signal.morlet2,widths,w=w))\n",
    "\n",
    "    return X_cwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3ae86d3-493c-4cff-9223-d6c4ac6c7e60",
   "metadata": {
    "id": "b3ae86d3-493c-4cff-9223-d6c4ac6c7e60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 18:06:09.739687: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-21 18:06:10.068503: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-21 18:06:10.803562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess import get_data\n",
    "from utils import getModel\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from evaluation import draw_learning_curves\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_model_with_cwt(dataset_conf, train_conf, results_path):\n",
    "\n",
    "    # remove the 'result' folder before training\n",
    "    if os.path.exists(results_path):\n",
    "        # Remove the folder and its contents\n",
    "        shutil.rmtree(results_path)\n",
    "        os.makedirs(results_path)\n",
    "\n",
    "    # Get the current 'IN' time to calculate the overall training time\n",
    "    in_exp = time.time()\n",
    "    # Create a file to store the path of the best model among several runs\n",
    "    best_models = open(results_path + \"/best models.txt\", \"w\")\n",
    "    # Create a file to store performance during training\n",
    "    log_write = open(results_path + \"/log.txt\", \"w\")\n",
    "\n",
    "    # Get dataset paramters\n",
    "    dataset = dataset_conf.get('name')\n",
    "    n_sub = dataset_conf.get('n_sub')\n",
    "    data_path = dataset_conf.get('data_path')\n",
    "    isStandard = dataset_conf.get('isStandard')\n",
    "    LOSO = dataset_conf.get('LOSO')\n",
    "    # Get training hyperparamters\n",
    "    batch_size = train_conf.get('batch_size')\n",
    "    epochs = train_conf.get('epochs')\n",
    "    patience = train_conf.get('patience')\n",
    "    lr = train_conf.get('lr')\n",
    "    LearnCurves = train_conf.get('LearnCurves') # Plot Learning Curves?\n",
    "    n_train = train_conf.get('n_train')\n",
    "    model_name = train_conf.get('model')\n",
    "    from_logits = train_conf.get('from_logits')\n",
    "\n",
    "    # Initialize variables\n",
    "    acc = np.zeros((n_sub, n_train))\n",
    "    kappa = np.zeros((n_sub, n_train))\n",
    "\n",
    "    # Iteration over subjects\n",
    "    # for sub in range(n_sub-1, n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n",
    "    for sub in range(n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n",
    "\n",
    "        print('\\nTraining on subject ', sub+1)\n",
    "        log_write.write( '\\nTraining on subject '+ str(sub+1) +'\\n')\n",
    "        # Initiating variables to save the best subject accuracy among multiple runs.\n",
    "        BestSubjAcc = 0\n",
    "        bestTrainingHistory = []\n",
    "\n",
    "        # Get training and test data\n",
    "        X_train, _, y_train_onehot, _, _, _ = get_data(\n",
    "            data_path, sub, dataset, LOSO = LOSO, isStandard = isStandard)\n",
    "        X_train = morlet_wavelet_transform(X_train)\n",
    "\n",
    "        # Divide the training data into training and validation\n",
    "        X_train, X_val, y_train_onehot, y_val_onehot = train_test_split(X_train, y_train_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Iteration over multiple runs\n",
    "        for train in range(n_train): # How many repetitions of training for subject i.\n",
    "            # Set the random seed for TensorFlow and NumPy random number generator.\n",
    "            # The purpose of setting a seed is to ensure reproducibility in random operations.\n",
    "            tf.random.set_seed(train+1)\n",
    "            np.random.seed(train+1)\n",
    "\n",
    "            # Get the current 'IN' time to calculate the 'run' training time\n",
    "            in_run = time.time()\n",
    "\n",
    "            # Create folders and files to save trained models for all runs\n",
    "            filepath = results_path + '/saved models with cwt/run-{}'.format(train+1)\n",
    "            if not os.path.exists(filepath):\n",
    "                os.makedirs(filepath)\n",
    "            filepath = filepath + '/subject-{}.h5'.format(sub+1)\n",
    "\n",
    "            # Create the model\n",
    "            model = getModel(model_name, dataset_conf, from_logits)\n",
    "            # Compile and train the model\n",
    "            model.compile(loss=CategoricalCrossentropy(from_logits=from_logits), optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "\n",
    "            # model.summary()\n",
    "            # plot_model(model, to_file='plot_model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "            callbacks = [\n",
    "                ModelCheckpoint(filepath, monitor='val_loss', verbose=0,\n",
    "                                save_best_only=True, save_weights_only=True, mode='min'),\n",
    "                ReduceLROnPlateau(monitor=\"val_loss\", factor=0.90, patience=20, verbose=0, min_lr=0.0001),\n",
    "                # EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=patience)\n",
    "            ]\n",
    "            history = model.fit(X_train, y_train_onehot, validation_data=(X_val, y_val_onehot),\n",
    "                                epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=0)\n",
    "\n",
    "            # Evaluate the performance of the trained model based on the validation data\n",
    "            # Here we load the Trained weights from the file saved in the hard\n",
    "            # disk, which should be the same as the weights of the current model.\n",
    "            model.load_weights(filepath)\n",
    "            y_pred = model.predict(X_val)\n",
    "\n",
    "            if from_logits:\n",
    "                y_pred = tf.nn.softmax(y_pred).numpy().argmax(axis=-1)\n",
    "            else:\n",
    "                y_pred = y_pred.argmax(axis=-1)\n",
    "\n",
    "            labels = y_val_onehot.argmax(axis=-1)\n",
    "            acc[sub, train]  = accuracy_score(labels, y_pred)\n",
    "            kappa[sub, train] = cohen_kappa_score(labels, y_pred)\n",
    "\n",
    "            # Get the current 'OUT' time to calculate the 'run' training time\n",
    "            out_run = time.time()\n",
    "            # Print & write performance measures for each run\n",
    "            info = 'Subject: {}   seed {}   time: {:.1f} m   '.format(sub+1, train+1, ((out_run-in_run)/60))\n",
    "            info = info + 'valid_acc: {:.4f}   valid_loss: {:.3f}'.format(acc[sub, train], min(history.history['val_loss']))\n",
    "            print(info)\n",
    "            log_write.write(info +'\\n')\n",
    "            # If current training run is better than previous runs, save the history.\n",
    "            if(BestSubjAcc < acc[sub, train]):\n",
    "                 BestSubjAcc = acc[sub, train]\n",
    "                 bestTrainingHistory = history\n",
    "\n",
    "        # Store the path of the best model among several runs\n",
    "        best_run = np.argmax(acc[sub,:])\n",
    "        filepath = '/saved models/run-{}/subject-{}.h5'.format(best_run+1, sub+1)+'\\n'\n",
    "        best_models.write(filepath)\n",
    "\n",
    "        # Plot Learning curves\n",
    "        if (LearnCurves == True):\n",
    "            print('Plot Learning Curves ....... ')\n",
    "            draw_learning_curves(bestTrainingHistory, sub+1)\n",
    "\n",
    "    # Get the current 'OUT' time to calculate the overall training time\n",
    "    out_exp = time.time()\n",
    "\n",
    "    # Print & write the validation performance using all seeds\n",
    "    head1 = head2 = '         '\n",
    "    for sub in range(n_sub):\n",
    "        head1 = head1 + 'sub_{}   '.format(sub+1)\n",
    "        head2 = head2 + '-----   '\n",
    "    head1 = head1 + '  average'\n",
    "    head2 = head2 + '  -------'\n",
    "    info = '\\n---------------------------------\\nValidation performance (acc %):'\n",
    "    info = info + '\\n---------------------------------\\n' + head1 +'\\n'+ head2\n",
    "    for run in range(n_train):\n",
    "        info = info + '\\nSeed {}:  '.format(run+1)\n",
    "        for sub in range(n_sub):\n",
    "            info = info + '{:.2f}   '.format(acc[sub, run]*100)\n",
    "        info = info + '  {:.2f}   '.format(np.average(acc[:, run])*100)\n",
    "    info = info + '\\n---------------------------------\\nAverage acc - all seeds: '\n",
    "    info = info + '{:.2f} %\\n\\nTrain Time  - all seeds: {:.1f}'.format(np.average(acc)*100, (out_exp-in_exp)/(60))\n",
    "    info = info + ' min\\n---------------------------------\\n'\n",
    "    print(info)\n",
    "    log_write.write(info+'\\n')\n",
    "\n",
    "    # Close open files\n",
    "    best_models.close()\n",
    "    log_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "uSnLeqyE5Xec",
   "metadata": {
    "id": "uSnLeqyE5Xec"
   },
   "outputs": [],
   "source": [
    "# If run on local machine\n",
    "root_data_path = '/home/quang'\n",
    "# If run on colab\n",
    "# root_data_path = '/content/drive/MyDrive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad597813-0ed4-4f17-a461-4975e124fcdd",
   "metadata": {
    "id": "ad597813-0ed4-4f17-a461-4975e124fcdd"
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    # Define dataset parameters\n",
    "    dataset = 'BCI2a'\n",
    "    in_samples = 1125\n",
    "    n_channels = 22\n",
    "    n_sub = 9\n",
    "    n_classes = 4\n",
    "    classes_labels = ['Left hand', 'Right hand','Foot','Tongue']\n",
    "    data_path = os.path.expanduser(root_data_path) + '/BCI Competition IV/BCI Competition IV-2a/BCI Competition IV 2a mat/'\n",
    "\n",
    "    # Create a folder to store the results of the experiment\n",
    "    results_path = os.getcwd() + \"/results\"\n",
    "    if not  os.path.exists(results_path):\n",
    "      os.makedirs(results_path)   # Create a new directory if it does not exist\n",
    "\n",
    "    # Set dataset paramters\n",
    "    dataset_conf = { 'name': dataset, 'n_classes': n_classes, 'cl_labels': classes_labels,\n",
    "                    'n_sub': n_sub, 'n_channels': n_channels, 'in_samples': in_samples,\n",
    "                    'data_path': data_path, 'isStandard': True, 'LOSO': False}\n",
    "    # Set training hyperparamters\n",
    "    train_conf = { 'batch_size': 64, 'epochs': 500, 'patience': 100, 'lr': 0.001,'n_train': 1,\n",
    "                  'LearnCurves': True, 'from_logits': False, 'model':'ATCNet_CWT'}\n",
    "\n",
    "    # Train the model\n",
    "    train_model_with_cwt(dataset_conf, train_conf, results_path)\n",
    "\n",
    "    # Evaluate the model based on the weights saved in the '/results' folder\n",
    "    model = getModel(train_conf.get('model'), dataset_conf)\n",
    "    test(model, dataset_conf, results_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be248d-2897-4584-a340-bbd8dce39af7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90be248d-2897-4584-a340-bbd8dce39af7",
    "outputId": "df3cfbeb-f57f-4119-8f56-daffd54468fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on subject  1\n"
     ]
    }
   ],
   "source": [
    "from preprocess import get_data\n",
    "from train import train_model\n",
    "from evaluation import test\n",
    "from utils import getModel\n",
    "import time\n",
    "import os\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ba211-9dfc-438f-8e6b-578bd93fe907",
   "metadata": {
    "id": "b98ba211-9dfc-438f-8e6b-578bd93fe907"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
