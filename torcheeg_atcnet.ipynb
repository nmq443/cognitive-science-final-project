{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81984ed7-3ae8-441c-9436-bfedda1af8cd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if run on colab\n",
    "#!pip install torcheeg\n",
    "#from google.colab import mount\n",
    "#drive.mount('/content/drive', force_remount=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc12ebc4-a1d2-4f87-a55a-b57284590a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torcheeg\n",
    "from torcheeg import transforms\n",
    "from torcheeg.datasets import BCICIV2aDataset\n",
    "from torcheeg.model_selection import KFoldGroupbyTrial\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheeg.models import ATCNet, EEGNet\n",
    "import torch\n",
    "\n",
    "from torcheeg.trainers import ClassifierTrainer\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c188ee-941b-4fcd-944f-ea31490ba99a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-13 16:28:06] INFO (torcheeg/MainThread) üîç | Processing EEG data. Processed EEG data has been cached to \u001b[92m./examples_pipeline/bciciv-2a\u001b[0m.\n",
      "[2024-05-13 16:28:06] INFO (torcheeg/MainThread) ‚è≥ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n",
      "[PROCESS]:   0%|                                                                                                                       | 0/18 [00:00<?, ?it/s]\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 0it [00:00, ?it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 1it [00:00,  2.10it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 41it [00:00, 93.57it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 76it [00:00, 156.92it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 113it [00:00, 212.32it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 145it [00:00, 238.91it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 182it [00:00, 273.45it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 216it [00:01, 290.80it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 254it [00:01, 314.93it/s]\u001b[A\n",
      "[PROCESS]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:12<00:00,  1.48it/s]\n",
      "[2024-05-13 16:28:19] INFO (torcheeg/MainThread) ‚úÖ | All processed EEG data has been cached to ./examples_pipeline/bciciv-2a.\n",
      "[2024-05-13 16:28:19] INFO (torcheeg/MainThread) üòä | Please set \u001b[92mio_path\u001b[0m to \u001b[92m./examples_pipeline/bciciv-2a\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n"
     ]
    }
   ],
   "source": [
    "dataset = BCICIV2aDataset(\n",
    "    root_path='./BCICIV-2a-mat/',\n",
    "    io_path=f'./examples_pipeline/bciciv-2a',\n",
    "    # skip_trial_with_artifacts=True,\n",
    "    # offline_transform=transforms.Compose([\n",
    "    #     transforms.BandDifferentialEntropy(apply_to_baseline=True),\n",
    "    #     transforms.To2d(apply_to_baseline=True),\n",
    "    #     transforms.ToTensor(apply_to_baseline=True)\n",
    "    # ]),\n",
    "    online_transform=transforms.Compose([\n",
    "        # transforms.To2d(apply_to_baseline=True),\n",
    "        # transforms.ToTensor(apply_to_baseline=True),\n",
    "        transforms.To2d(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.CWTSpectrum(apply_to_baseline=True),\n",
    "        # transforms.BandDifferentialEntropy(apply_to_baseline=True),\n",
    "        # transforms.BaselineRemoval(),\n",
    "    ]),\n",
    "    label_transform=transforms.Compose([\n",
    "        transforms.Select('label'),\n",
    "        transforms.Lambda(lambda x: x - 1)\n",
    "    ]),\n",
    "    chunk_size=7*250,\n",
    "    num_worker=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355ef69c-bc37-4e98-aae7-36eab6edac00",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset's info: \n",
      "      start_at  end_at   clip_id subject_id  trial_id session subject  run  \\\n",
      "0          251    2001    A06E_0        A06         0       E     A06    3   \n",
      "1         2254    4004    A06E_1        A06         1       E     A06    3   \n",
      "2         4172    5922    A06E_2        A06         2       E     A06    3   \n",
      "3         6124    7874    A06E_3        A06         3       E     A06    3   \n",
      "4         8132    9882    A06E_4        A06         4       E     A06    3   \n",
      "...        ...     ...       ...        ...       ...     ...     ...  ...   \n",
      "5179     86751   88501  A05T_283        A05        43       T     A05    8   \n",
      "5180     88657   90407  A05T_284        A05        44       T     A05    8   \n",
      "5181     90585   92335  A05T_285        A05        45       T     A05    8   \n",
      "5182     92699   94449  A05T_286        A05        46       T     A05    8   \n",
      "5183     94758   96508  A05T_287        A05        47       T     A05    8   \n",
      "\n",
      "      label  _record_id  \n",
      "0         1   _record_0  \n",
      "1         2   _record_0  \n",
      "2         2   _record_0  \n",
      "3         1   _record_0  \n",
      "4         2   _record_0  \n",
      "...     ...         ...  \n",
      "5179      3  _record_17  \n",
      "5180      4  _record_17  \n",
      "5181      3  _record_17  \n",
      "5182      1  _record_17  \n",
      "5183      3  _record_17  \n",
      "\n",
      "[5184 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset's info: \")\n",
    "print(dataset.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c73c66-fee0-4ea9-a0b3-05f43ac8e12f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "k_fold = KFoldGroupbyTrial(\n",
    "    n_splits=10,\n",
    "    split_path='./examples_pipeline/split',\n",
    "    shuffle=True,\n",
    "    random_state=44\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fcace-ca0f-4abd-9de5-4075aa01394f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-13 16:29:39] INFO (torcheeg/MainThread) üìä | Create the split of train and test set.\n",
      "[2024-05-13 16:29:39] INFO (torcheeg/MainThread) üòä | Please set \u001b[92msplit_path\u001b[0m to \u001b[92m./examples_pipeline/split\u001b[0m for the next run, if you want to use the same setting for the experiment.\n",
      "/home/quang/yes/envs/cognitive-computing/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /opt/conda/conda-bld/pytorch_1712608958871/work/aten/src/ATen/native/Convolution.cpp:1031.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/quang/yes/envs/cognitive-computing/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Missing logger folder: examples_pipeline/model/0/lightning_logs\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | ATCNet           | 88.7 K\n",
      "1 | ce_fn         | CrossEntropyLoss | 0     \n",
      "2 | train_loss    | MeanMetric       | 0     \n",
      "3 | val_loss      | MeanMetric       | 0     \n",
      "4 | test_loss     | MeanMetric       | 0     \n",
      "5 | train_metrics | MetricCollection | 0     \n",
      "6 | val_metrics   | MetricCollection | 0     \n",
      "7 | test_metrics  | MetricCollection | 0     \n",
      "---------------------------------------------------\n",
      "88.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "88.7 K    Total params\n",
      "0.355     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 50/68 [02:54<01:02,  0.29it/s, v_num=0, train_loss=1.390, train_accuracy=0.250]"
     ]
    }
   ],
   "source": [
    "DEVICE = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = ATCNet(\n",
    "    num_classes=4,\n",
    "    num_electrodes=22,\n",
    "    chunk_size=7*250,\n",
    ")\n",
    "\n",
    "for i, (train_dataset, val_dataset) in enumerate(k_fold.split(dataset)):\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    trainer = ClassifierTrainer(\n",
    "        model=model,\n",
    "        num_classes=4,\n",
    "        lr=1e-4,\n",
    "        weight_decay=1e-4,\n",
    "        accelerator=DEVICE\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        train_loader,\n",
    "        val_loader, \n",
    "        max_epochs=10,\n",
    "        default_root_dir=f'./examples_pipeline/atcnet_model/{i}',\n",
    "        callbacks=[pl.callbacks.ModelCheckpoint(save_last=True)],\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=True,\n",
    "        limit_val_batches=0.0\n",
    "    )\n",
    "\n",
    "    score = trainer.test(\n",
    "        val_loader,\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=True\n",
    "    )[0]\n",
    "    print(f\"Fold {i} test accuracy: {score['test_accuracy']: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b195ac2-1732-45f8-91b3-536e44021282",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "atc_weights_path = './weights/atc_weights.pt'\n",
    "torch.save(model.state_dict(), atc_weights_path)\n",
    "# to load weight:\n",
    "# model.load_state_dict(torch.load(atc_weights_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
