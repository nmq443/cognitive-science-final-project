{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81984ed7-3ae8-441c-9436-bfedda1af8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if run on colab\n",
    "#!pip install torcheeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc12ebc4-a1d2-4f87-a55a-b57284590a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torcheeg\n",
    "from torcheeg import transforms\n",
    "from torcheeg.datasets import BCICIV2aDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c188ee-941b-4fcd-944f-ea31490ba99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-13 15:20:23] INFO (torcheeg/MainThread) üîç | Processing EEG data. Processed EEG data has been cached to \u001b[92m./examples_pipeline/bciciv-2a\u001b[0m.\n",
      "[2024-05-13 15:20:23] INFO (torcheeg/MainThread) ‚è≥ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n",
      "[PROCESS]:   0%|                                       | 0/18 [00:00<?, ?it/s]\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 0it [00:00, ?it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 1it [00:00,  2.15it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 48it [00:00, 111.86it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 86it [00:00, 178.09it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 123it [00:00, 228.51it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 157it [00:00, 253.52it/s]\u001b[A\n",
      "[RECORD ./BCICIV-2a-mat/A06E.mat]: 195it [00:00, 287.36it/s]\u001b[A\n",
      "[PROCESS]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:10<00:00,  1.66it/s]\n",
      "[2024-05-13 15:20:36] INFO (torcheeg/MainThread) ‚úÖ | All processed EEG data has been cached to ./examples_pipeline/bciciv-2a.\n",
      "[2024-05-13 15:20:36] INFO (torcheeg/MainThread) üòä | Please set \u001b[92mio_path\u001b[0m to \u001b[92m./examples_pipeline/bciciv-2a\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n"
     ]
    }
   ],
   "source": [
    "dataset = BCICIV2aDataset(\n",
    "    root_path='./BCICIV-2a-mat/',\n",
    "    io_path=f'./examples_pipeline/bciciv-2a',\n",
    "    skip_trial_with_artifacts=True,\n",
    "    # offline_transform=transforms.Compose([\n",
    "    #     transforms.BandDifferentialEntropy(apply_to_baseline=True),\n",
    "    #     transforms.To2d(apply_to_baseline=True),\n",
    "    #     transforms.ToTensor(apply_to_baseline=True)\n",
    "    # ]),\n",
    "    online_transform=transforms.Compose([\n",
    "        # transforms.To2d(apply_to_baseline=True),\n",
    "        # transforms.ToTensor(apply_to_baseline=True),\n",
    "        transforms.To2d(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.CWTSpectrum(apply_to_baseline=True),\n",
    "        # transforms.BandDifferentialEntropy(apply_to_baseline=True),\n",
    "        # transforms.BaselineRemoval(),\n",
    "    ]),\n",
    "    label_transform=transforms.Compose([\n",
    "        transforms.Select('label'),\n",
    "        transforms.Lambda(lambda x: x - 1)\n",
    "    ]),\n",
    "    chunk_size=1750,\n",
    "    num_worker=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "355ef69c-bc37-4e98-aae7-36eab6edac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset's info: \n",
      "      start_at  end_at   clip_id subject_id  trial_id session subject  run  \\\n",
      "0          251    2001    A06E_0        A06         0       E     A06    3   \n",
      "1         2254    4004    A06E_1        A06         1       E     A06    3   \n",
      "2         4172    5922    A06E_2        A06         2       E     A06    3   \n",
      "3         6124    7874    A06E_3        A06         3       E     A06    3   \n",
      "4        10243   11993    A06E_4        A06         5       E     A06    3   \n",
      "...        ...     ...       ...        ...       ...     ...     ...  ...   \n",
      "4691     86751   88501  A05T_257        A05        43       T     A05    8   \n",
      "4692     88657   90407  A05T_258        A05        44       T     A05    8   \n",
      "4693     90585   92335  A05T_259        A05        45       T     A05    8   \n",
      "4694     92699   94449  A05T_260        A05        46       T     A05    8   \n",
      "4695     94758   96508  A05T_261        A05        47       T     A05    8   \n",
      "\n",
      "      label  _record_id  \n",
      "0         1   _record_0  \n",
      "1         2   _record_0  \n",
      "2         2   _record_0  \n",
      "3         1   _record_0  \n",
      "4         1   _record_0  \n",
      "...     ...         ...  \n",
      "4691      3  _record_17  \n",
      "4692      4  _record_17  \n",
      "4693      3  _record_17  \n",
      "4694      1  _record_17  \n",
      "4695      3  _record_17  \n",
      "\n",
      "[4696 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset's info: \")\n",
    "print(dataset.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c73c66-fee0-4ea9-a0b3-05f43ac8e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg.model_selection import KFoldGroupbyTrial\n",
    "\n",
    "k_fold = KFoldGroupbyTrial(\n",
    "    n_splits=10,\n",
    "    split_path='./examples_pipeline/split',\n",
    "    shuffle=True,\n",
    "    random_state=44\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5fcace-ca0f-4abd-9de5-4075aa01394f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-13 15:21:11] INFO (torcheeg/MainThread) üìä | Create the split of train and test set.\n",
      "[2024-05-13 15:21:11] INFO (torcheeg/MainThread) üòä | Please set \u001b[92msplit_path\u001b[0m to \u001b[92m./examples_pipeline/split\u001b[0m for the next run, if you want to use the same setting for the experiment.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=4.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorcheeg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassifierTrainer\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_dataset, val_dataset) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(k_fold\u001b[38;5;241m.\u001b[39msplit(dataset)):\n\u001b[1;32m      9\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     10\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     11\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     12\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     val_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     15\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[1;32m     16\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     17\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     )\n",
      "File \u001b[0;32m~/yes/envs/cognitive-computing/lib/python3.10/site-packages/torcheeg/model_selection/k_fold_groupby_trial.py:133\u001b[0m, in \u001b[0;36mKFoldGroupbyTrial.split\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    129\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124müòä | Please set \u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[92msplit_path\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m to \u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[92m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m for the next run, if you want to use the same setting for the experiment.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    132\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_path)\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_info_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124müìä | Detected existing split of train and test set, use existing split from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m     )\n",
      "File \u001b[0;32m~/yes/envs/cognitive-computing/lib/python3.10/site-packages/torcheeg/model_selection/k_fold_groupby_trial.py:89\u001b[0m, in \u001b[0;36mKFoldGroupbyTrial.split_info_constructor\u001b[0;34m(self, info)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial_id \u001b[38;5;129;01min\u001b[39;00m trial_ids:\n\u001b[1;32m     88\u001b[0m     trial_info \u001b[38;5;241m=\u001b[39m subject_info[subject_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrial_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m trial_id]\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (train_index,\n\u001b[1;32m     90\u001b[0m             test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_fold\u001b[38;5;241m.\u001b[39msplit(trial_info)):\n\u001b[1;32m     91\u001b[0m         train_info \u001b[38;5;241m=\u001b[39m trial_info\u001b[38;5;241m.\u001b[39miloc[train_index]\n\u001b[1;32m     92\u001b[0m         test_info \u001b[38;5;241m=\u001b[39m trial_info\u001b[38;5;241m.\u001b[39miloc[test_index]\n",
      "File \u001b[0;32m~/yes/envs/cognitive-computing/lib/python3.10/site-packages/sklearn/model_selection/_split.py:370\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    368\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    371\u001b[0m         (\n\u001b[1;32m    372\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    374\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    375\u001b[0m     )\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=4."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torcheeg.models import ATCNet, EEGNet\n",
    "\n",
    "from torcheeg.trainers import ClassifierTrainer\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "for i, (train_dataset, val_dataset) in enumerate(k_fold.split(dataset)):\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # model = ATCNet(\n",
    "    #     num_classes=4,\n",
    "    #     num_electrodes=22,\n",
    "    #     chunk_size=128,\n",
    "    #     in_channels=22,\n",
    "    #     num_windows=3\n",
    "    # )\n",
    "    model = EEGNet(\n",
    "        chunk_size=1750,\n",
    "        num_electrodes=22,\n",
    "        num_classes=4,\n",
    "        dropout=0.5\n",
    "    )\n",
    "\n",
    "    trainer = ClassifierTrainer(\n",
    "        model=model,\n",
    "        num_classes=4,\n",
    "        lr=1e-4,\n",
    "        weight_decay=1e-4,\n",
    "        accelerator='gpu'\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        train_loader,\n",
    "        val_loader, \n",
    "        max_epochs=100,\n",
    "        default_root_dir=f'./examples_pipeline/model/{i}',\n",
    "        callbacks=[pl.callbacks.ModelCheckpoint(save_last=True)],\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=True,\n",
    "        limit_val_batches=0.0\n",
    "    )\n",
    "\n",
    "    score = trainer.test(\n",
    "        val_loader,\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=True\n",
    "    )[0]\n",
    "    print(f\"Fold {i} test accuracy: {score['test_accuracy']: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b195ac2-1732-45f8-91b3-536e44021282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
