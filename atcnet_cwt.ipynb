{"metadata":{"colab":{"provenance":[],"include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8455971,"sourceType":"datasetVersion","datasetId":5039749}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/nmq443/cognitive-science-final-project/blob/main/atcnet_cwt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"# if run on colab\n# from google.colab import drive\n# drive.mount('/content/drive',force_remount=True)","metadata":{"id":"SqN8BDu78pBn","outputId":"32a46787-39b5-47d6-b161-727fb7271f60","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-05-27T02:21:43.946709Z","iopub.execute_input":"2024-05-27T02:21:43.947109Z","iopub.status.idle":"2024-05-27T02:21:43.972818Z","shell.execute_reply.started":"2024-05-27T02:21:43.947079Z","shell.execute_reply":"2024-05-27T02:21:43.971368Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip uninstall -y keras\n!pip install keras==2.15.0","metadata":{"id":"4gFjQCn-xWj5","outputId":"ad3e89d8-98b8-475b-8c22-2e448a56edb7","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-05-27T02:21:43.975638Z","iopub.execute_input":"2024-05-27T02:21:43.976007Z","iopub.status.idle":"2024-05-27T02:22:05.952479Z","shell.execute_reply.started":"2024-05-27T02:21:43.975977Z","shell.execute_reply":"2024-05-27T02:22:05.951214Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: keras 3.2.1\nUninstalling keras-3.2.1:\n  Successfully uninstalled keras-3.2.1\nCollecting keras==2.15.0\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/nmq443/cognitive-science-final-project.git","metadata":{"id":"D7J4mCDz-ZYJ","outputId":"d8679eeb-dba4-4935-dfef-81edb7a23d04","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-05-27T02:22:05.954174Z","iopub.execute_input":"2024-05-27T02:22:05.954538Z","iopub.status.idle":"2024-05-27T02:22:08.981025Z","shell.execute_reply.started":"2024-05-27T02:22:05.954504Z","shell.execute_reply":"2024-05-27T02:22:08.979383Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'cognitive-science-final-project'...\nremote: Enumerating objects: 300, done.\u001b[K\nremote: Counting objects: 100% (133/133), done.\u001b[K\nremote: Compressing objects: 100% (120/120), done.\u001b[K\nremote: Total 300 (delta 65), reused 39 (delta 13), pack-reused 167\u001b[K\nReceiving objects: 100% (300/300), 5.88 MiB | 11.71 MiB/s, done.\nResolving deltas: 100% (145/145), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\n# if run on colab\n# os.chdir('/content/cognitive-science-final-project/')\n\n# if run on kaggle\nos.chdir('cognitive-science-final-project/')\nos.getcwd()","metadata":{"id":"pWYGvzsx-mIl","outputId":"68316683-f11c-4f56-8f24-150b57dd405b","colab":{"base_uri":"https://localhost:8080/","height":35},"execution":{"iopub.status.busy":"2024-05-27T02:22:08.982976Z","iopub.execute_input":"2024-05-27T02:22:08.983412Z","iopub.status.idle":"2024-05-27T02:22:08.993452Z","shell.execute_reply.started":"2024-05-27T02:22:08.983373Z","shell.execute_reply":"2024-05-27T02:22:08.992205Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/cognitive-science-final-project'"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport time\nimport shutil\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import cohen_kappa_score\nfrom preprocess import get_data\nfrom utils import getModel\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom evaluation import draw_learning_curves\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import accuracy_score\n\ndef train_model(dataset_conf, train_conf, results_path, cwt=True):\n\n    # remove the 'result' folder before training\n    if os.path.exists(results_path):\n        # Remove the folder and its contents\n        shutil.rmtree(results_path)\n        os.makedirs(results_path)\n        \n    os.makedirs(results_path + '/saved models cwt')\n\n    # Get the current 'IN' time to calculate the overall training time\n    in_exp = time.time()\n    # Create a file to store the path of the best model among several runs\n    best_models = open(results_path + \"/best models_cwt.txt\", \"w\")\n    # Create a file to store performance during training\n    log_write = open(results_path + \"/log.txt\", \"w\")\n\n    # Get dataset paramters\n    dataset = dataset_conf.get('name')\n    n_sub = dataset_conf.get('n_sub')\n    data_path = dataset_conf.get('data_path')\n    isStandard = dataset_conf.get('isStandard')\n    LOSO = dataset_conf.get('LOSO')\n    # Get training hyperparamters\n    batch_size = train_conf.get('batch_size')\n    epochs = train_conf.get('epochs')\n    patience = train_conf.get('patience')\n    lr = train_conf.get('lr')\n    LearnCurves = train_conf.get('LearnCurves') # Plot Learning Curves?\n    n_train = train_conf.get('n_train')\n    model_name = train_conf.get('model')\n    from_logits = train_conf.get('from_logits')\n\n    # Initialize variables\n    acc = np.zeros((n_sub, n_train))\n    kappa = np.zeros((n_sub, n_train))\n\n    # Iteration over subjects\n    # for sub in range(n_sub-1, n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n    for sub in range(n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n\n        print('\\nTraining on subject ', sub+1)\n        log_write.write( '\\nTraining on subject '+ str(sub+1) +'\\n')\n        # Initiating variables to save the best subject accuracy among multiple runs.\n        BestSubjAcc = 0\n        bestTrainingHistory = []\n\n        # Get training and test data\n        X_train, _, y_train_onehot, _, _, _ = get_data(\n            data_path, sub, dataset, LOSO = LOSO, isStandard = isStandard)\n\n        if cwt:\n            X_train = morlet_wavelet_transform(X_train)\n\n        # Divide the training data into training and validation\n        X_train, X_val, y_train_onehot, y_val_onehot = train_test_split(X_train, y_train_onehot, test_size=0.2, random_state=42)\n\n        # Iteration over multiple runs\n        for train in range(n_train): # How many repetitions of training for subject i.\n            # Set the random seed for TensorFlow and NumPy random number generator.\n            # The purpose of setting a seed is to ensure reproducibility in random operations.\n            tf.random.set_seed(train+1)\n            np.random.seed(train+1)\n\n            # Get the current 'IN' time to calculate the 'run' training time\n            in_run = time.time()\n\n            # Create folders and files to save trained models for all runs\n            filepath = results_path + '/saved models cwt/run-{}'.format(train+1)\n            if not os.path.exists(filepath):\n                os.makedirs(filepath)\n            # filepath = filepath + '/subject-{}.weights.h5'.format(sub+1)\n            filepath = filepath + '/subject-{}.h5'.format(sub+1)\n\n            # Create the model\n            model = getModel(model_name, dataset_conf, from_logits)\n            # Compile and train the model\n            model.compile(loss=CategoricalCrossentropy(from_logits=from_logits), optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n\n            # model.summary()\n            # plot_model(model, to_file='plot_model.png', show_shapes=True, show_layer_names=True)\n\n            callbacks = [\n                ModelCheckpoint(filepath, monitor='val_loss', verbose=0,\n                                save_best_only=True, save_weights_only=True, mode='min'),\n                ReduceLROnPlateau(monitor=\"val_loss\", factor=0.90, patience=20, verbose=0, min_lr=0.0001),\n                # EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=patience)\n            ]\n\n            history = model.fit(X_train, y_train_onehot, validation_data=(X_val, y_val_onehot),\n                                epochs=epochs, batch_size=batch_size, verbose=0)\n\n            # Evaluate the performance of the trained model based on the validation data\n            # Here we load the Trained weights from the file saved in the hard\n            # disk, which should be the same as the weights of the current model.\n#             model.load_weights(filepath)\n            y_pred = model.predict(X_val)\n\n            if from_logits:\n                y_pred = tf.nn.softmax(y_pred).numpy().argmax(axis=-1)\n            else:\n                y_pred = y_pred.argmax(axis=-1)\n\n            labels = y_val_onehot.argmax(axis=-1)\n            acc[sub, train]  = accuracy_score(labels, y_pred)\n            kappa[sub, train] = cohen_kappa_score(labels, y_pred)\n\n            # Get the current 'OUT' time to calculate the 'run' training time\n            out_run = time.time()\n            # Print & write performance measures for each run\n            info = 'Subject: {}   seed {}   time: {:.1f} m   '.format(sub+1, train+1, ((out_run-in_run)/60))\n            info = info + 'valid_acc: {:.4f}   valid_loss: {:.3f}'.format(acc[sub, train], min(history.history['val_loss']))\n            print(info)\n            log_write.write(info +'\\n')\n            # If current training run is better than previous runs, save the history.\n            if(BestSubjAcc < acc[sub, train]):\n                 BestSubjAcc = acc[sub, train]\n                 bestTrainingHistory = history\n\n        # Store the path of the best model among several runs\n        best_run = np.argmax(acc[sub,:])\n        # filepath = '/saved models cwt/run-{}/subject-{}.weights.h5'.format(best_run+1, sub+1)+'\\n'\n        filepath = '/saved models cwt/run-{}/subject-{}.h5'.format(best_run+1, sub+1)+'\\n'\n        best_models.write(filepath)\n\n        # Plot Learning curves\n        if (LearnCurves == True):\n            print('Plot Learning Curves ....... ')\n            draw_learning_curves(bestTrainingHistory, sub+1)\n\n    # Get the current 'OUT' time to calculate the overall training time\n    out_exp = time.time()\n\n    # Print & write the validation performance using all seeds\n    head1 = head2 = '         '\n    for sub in range(n_sub):\n        head1 = head1 + 'sub_{}   '.format(sub+1)\n        head2 = head2 + '-----   '\n    head1 = head1 + '  average'\n    head2 = head2 + '  -------'\n    info = '\\n---------------------------------\\nValidation performance (acc %):'\n    info = info + '\\n---------------------------------\\n' + head1 +'\\n'+ head2\n    for run in range(n_train):\n        info = info + '\\nSeed {}:  '.format(run+1)\n        for sub in range(n_sub):\n            info = info + '{:.2f}   '.format(acc[sub, run]*100)\n        info = info + '  {:.2f}   '.format(np.average(acc[:, run])*100)\n    info = info + '\\n---------------------------------\\nAverage acc - all seeds: '\n    info = info + '{:.2f} %\\n\\nTrain Time  - all seeds: {:.1f}'.format(np.average(acc)*100, (out_exp-in_exp)/(60))\n    info = info + ' min\\n---------------------------------\\n'\n    print(info)\n    log_write.write(info+'\\n')\n\n    # Close open files\n    best_models.close()\n    log_write.close()","metadata":{"id":"21dabdfc-b1e4-42a8-bd1b-43aa389c2599","execution":{"iopub.status.busy":"2024-05-27T02:22:08.996898Z","iopub.execute_input":"2024-05-27T02:22:08.997293Z","iopub.status.idle":"2024-05-27T02:22:26.190334Z","shell.execute_reply.started":"2024-05-27T02:22:08.997261Z","shell.execute_reply":"2024-05-27T02:22:26.189029Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-05-27 02:22:12.750357: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-27 02:22:12.750482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-27 02:22:12.907951: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"def make_results_dir():\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getModel(model_name, dataset_conf, from_logits = False):\n\n    n_classes = dataset_conf.get('n_classes')\n    n_channels = dataset_conf.get('n_channels')\n    in_samples = dataset_conf.get('in_samples')\n\n    # Select the model\n    if(model_name == 'ATCNet'):\n        # Train using the proposed ATCNet model: https://ieeexplore.ieee.org/document/9852687\n        model = models.ATCNet_(\n            # Dataset parameters\n            n_classes = n_classes,\n            in_chans = n_channels,\n            in_samples = in_samples,\n            # Sliding window (SW) parameter\n            n_windows = 5,\n            # Attention (AT) block parameter\n            attention = 'mha', # Options: None, 'mha','mhla', 'cbam', 'se'\n            # Convolutional (CV) block parameters\n            eegn_F1 = 16,\n            eegn_D = 2,\n            eegn_kernelSize = 64,\n            eegn_poolSize = 7,\n            eegn_dropout = 0.3,\n            # Temporal convolutional (TC) block parameters\n            tcn_depth = 2,\n            tcn_kernelSize = 4,\n            tcn_filters = 32,\n            tcn_dropout = 0.3,\n            tcn_activation='elu',\n            )\n    elif(model_name == 'ATCNet_CWT'):\n        model = models.ATCNet_CWT(\n            # Dataset parameters\n            n_classes = n_classes,\n            in_chans = n_channels,\n            in_samples = in_samples,\n            # Sliding window (SW) parameter\n            n_windows = 5,\n            # Attention (AT) block parameter\n            attention = 'mha', # Options: None, 'mha','mhla', 'cbam', 'se'\n            # Convolutional (CV) block parameters\n            eegn_F1 = 16,\n            eegn_D = 2,\n            eegn_kernelSize = 64,\n            eegn_poolSize = 7,\n            eegn_dropout = 0.3,\n            # Temporal convolutional (TC) block parameters\n            tcn_depth = 2,\n            tcn_kernelSize = 4,\n            tcn_filters = 32,\n            tcn_dropout = 0.3,\n            tcn_activation='elu',\n        )\n    elif(model_name == 'TCNet_Fusion'):\n        # Train using TCNet_Fusion: https://doi.org/10.1016/j.bspc.2021.102826\n        model = models.TCNet_Fusion(n_classes = n_classes, Chans=n_channels, Samples=in_samples)\n    elif(model_name == 'EEGTCNet'):\n        # Train using EEGTCNet: https://arxiv.org/abs/2006.00622\n        model = models.EEGTCNet(n_classes = n_classes, Chans=n_channels, Samples=in_samples)\n    elif(model_name == 'EEGNet'):\n        # Train using EEGNet: https://arxiv.org/abs/1611.08024\n        model = models.EEGNet_classifier(n_classes = n_classes, Chans=n_channels, Samples=in_samples)\n    elif(model_name == 'EEGNeX'):\n        # Train using EEGNeX: https://arxiv.org/abs/2207.12369\n        model = models.EEGNeX_8_32(n_timesteps = in_samples , n_features = n_channels, n_outputs = n_classes)\n    elif(model_name == 'DeepConvNet'):\n        # Train using DeepConvNet: https://doi.org/10.1002/hbm.23730\n        model = models.DeepConvNet(nb_classes = n_classes , Chans = n_channels, Samples = in_samples)\n    elif(model_name == 'ShallowConvNet'):\n        # Train using ShallowConvNet: https://doi.org/10.1002/hbm.23730\n        model = models.ShallowConvNet(nb_classes = n_classes , Chans = n_channels, Samples = in_samples)\n    elif(model_name == 'MBEEG_SENet'):\n        # Train using MBEEG_SENet: https://www.mdpi.com/2075-4418/12/4/995\n        model = models.MBEEG_SENet(nb_classes = n_classes , Chans = n_channels, Samples = in_samples)\n\n    else:\n        raise Exception(\"'{}' model is not supported yet!\".format(model_name))\n\n    return model","metadata":{"id":"749100ae-592a-47f7-9bea-1171076b87b9","execution":{"iopub.status.busy":"2024-05-27T02:22:26.192009Z","iopub.execute_input":"2024-05-27T02:22:26.192788Z","iopub.status.idle":"2024-05-27T02:22:26.210395Z","shell.execute_reply.started":"2024-05-27T02:22:26.192751Z","shell.execute_reply":"2024-05-27T02:22:26.208995Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def test(model, dataset_conf, results_path, allRuns = True):\n    # Open the  \"Log\" file to write the evaluation results\n    log_write = open(results_path + \"/log.txt\", \"a\")\n\n    # Get dataset paramters\n    dataset = dataset_conf.get('name')\n    n_classes = dataset_conf.get('n_classes')\n    n_sub = dataset_conf.get('n_sub')\n    data_path = dataset_conf.get('data_path')\n    isStandard = dataset_conf.get('isStandard')\n    LOSO = dataset_conf.get('LOSO')\n    classes_labels = dataset_conf.get('cl_labels')\n\n    # Test the performance based on several runs (seeds)\n    runs = os.listdir(results_path+\"/saved models cwt\")\n    # Initialize variables\n    acc = np.zeros((n_sub, len(runs)))\n    kappa = np.zeros((n_sub, len(runs)))\n    cf_matrix = np.zeros([n_sub, len(runs), n_classes, n_classes])\n\n    # Iteration over subjects\n    # for sub in range(n_sub-1, n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n    inference_time = 0 #  inference_time: classification time for one trial\n    for sub in range(n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n        # Load data\n        _, _, _, X_test, _, y_test_onehot = get_data(data_path, sub, dataset, LOSO = LOSO, isStandard = isStandard)\n\n        # Iteration over runs (seeds)\n        for seed in range(len(runs)):\n            # Load the model of the seed.\n            # model.load_weights('{}/saved models cwt/{}/subject-{}.weights.h5'.format(results_path, runs[seed], sub+1))\n            model.load_weights('{}/saved models cwt/{}/subject-{}.h5'.format(results_path, runs[seed], sub+1))\n\n\n            inference_time = time.time()\n            # Predict MI task\n            y_pred = model.predict(X_test).argmax(axis=-1)\n            inference_time = (time.time() - inference_time)/X_test.shape[0]\n            # Calculate accuracy and K-score\n            labels = y_test_onehot.argmax(axis=-1)\n            acc[sub, seed]  = accuracy_score(labels, y_pred)\n            kappa[sub, seed] = cohen_kappa_score(labels, y_pred)\n            # Calculate and draw confusion matrix\n            cf_matrix[sub, seed, :, :] = confusion_matrix(labels, y_pred, normalize='true')\n            # draw_confusion_matrix(cf_matrix[sub, seed, :, :], str(sub+1), results_path, classes_labels)\n\n    # Print & write the average performance measures for all subjects\n    head1 = head2 = '                  '\n    for sub in range(n_sub):\n        head1 = head1 + 'sub_{}   '.format(sub+1)\n        head2 = head2 + '-----   '\n    head1 = head1 + '  average'\n    head2 = head2 + '  -------'\n    info = '\\n' + head1 +'\\n'+ head2\n    info = '\\n---------------------------------\\nTest performance (acc & k-score):\\n'\n    info = info + '---------------------------------\\n' + head1 +'\\n'+ head2\n    for run in range(len(runs)):\n        info = info + '\\nSeed {}: '.format(run+1)\n        info_acc = '(acc %)   '\n        info_k = '        (k-sco)   '\n        for sub in range(n_sub):\n            info_acc = info_acc + '{:.2f}   '.format(acc[sub, run]*100)\n            info_k = info_k + '{:.3f}   '.format(kappa[sub, run])\n        info_acc = info_acc + '  {:.2f}   '.format(np.average(acc[:, run])*100)\n        info_k = info_k + '  {:.3f}   '.format(np.average(kappa[:, run]))\n        info = info + info_acc + '\\n' + info_k\n    info = info + '\\n----------------------------------\\nAverage - all seeds (acc %): '\n    info = info + '{:.2f}\\n                    (k-sco): '.format(np.average(acc)*100)\n    info = info + '{:.3f}\\n\\nInference time: {:.2f}'.format(np.average(kappa), inference_time * 1000)\n    info = info + ' ms per trial\\n----------------------------------\\n'\n    print(info)\n    log_write.write(info+'\\n')\n\n    # Draw a performance bar chart for all subjects\n    draw_performance_barChart(n_sub, acc.mean(1), 'Accuracy')\n    draw_performance_barChart(n_sub, kappa.mean(1), 'k-score')\n    # Draw confusion matrix for all subjects (average)\n    draw_confusion_matrix(cf_matrix.mean((0,1)), 'All', results_path, classes_labels)\n    # Close opened file\n    log_write.close()","metadata":{"id":"e2c78ac7-2b27-43cc-98fa-076646a60a36","execution":{"iopub.status.busy":"2024-05-27T02:22:26.212380Z","iopub.execute_input":"2024-05-27T02:22:26.212834Z","iopub.status.idle":"2024-05-27T02:22:26.242660Z","shell.execute_reply.started":"2024-05-27T02:22:26.212796Z","shell.execute_reply":"2024-05-27T02:22:26.241175Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# from train import train_model\n# from utils import getModel\n# from evaluation import test\nimport os\nimport shutil\nimport time\nimport numpy as np\nfrom preprocess import get_data\nimport models","metadata":{"id":"69b5e6d4-7029-4971-87fb-32e0c6a91caf","execution":{"iopub.status.busy":"2024-05-27T02:22:26.244266Z","iopub.execute_input":"2024-05-27T02:22:26.244766Z","iopub.status.idle":"2024-05-27T02:22:26.261564Z","shell.execute_reply.started":"2024-05-27T02:22:26.244724Z","shell.execute_reply":"2024-05-27T02:22:26.260208Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# if run on colab\n# root_datapath = '/content/drive/MyDrive'\n\n# if run on local machine\n# root_datapath = '/home/quang'\n\n# if run on kaggle\nroot_datapath = '/kaggle/input/bci-competition-iv-2a'","metadata":{"id":"4e8e9e11-c178-4c12-b46a-0c26d075d7af","execution":{"iopub.status.busy":"2024-05-27T02:22:26.263026Z","iopub.execute_input":"2024-05-27T02:22:26.263440Z","iopub.status.idle":"2024-05-27T02:22:26.280377Z","shell.execute_reply.started":"2024-05-27T02:22:26.263403Z","shell.execute_reply":"2024-05-27T02:22:26.279072Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport random\nfrom sklearn.linear_model import LinearRegression\nfrom scipy import signal\nimport matplotlib.pyplot as plt\n\n\ndef morlet_wavelet_transform(X,fs=250,freq_range=(1,15),freq_bins=100,w=5):\n    '''\n    Discrete continous wavelet transform of eeg data convolved with complex morlet wavelet\n    INPUTS:\n    X - EEG data (num_trials, num_eeg_electrodes, time_bins,1)\n    fs - sampling rate in Hz\n    freq_range - tuple containing min and max freq range to perform analysis within\n    freq_bins - number of points between freq range being analyzed\n    w - Omega0 for complex morlet wavelet\n    OUTPUTS:\n    X_cwt - Wavlet transformed eeg data (num_trials, num_eeg_electrodes,freq_bins,time_bins)\n    '''\n\n    N_trials, _, N_eegs, time_bins = X.shape\n\n    # values for cwt\n    freq = np.linspace(freq_range[0],freq_range[1],freq_bins)\n    widths = w * fs / (2 * freq * np.pi)\n    X_cwt = np.zeros((N_trials, N_eegs, widths.shape[0], time_bins))\n\n    print('Performing discrete CWT convolutions...')\n\n    for trial in range(N_trials):\n        for eeg in range(N_eegs):\n            X_cwt[trial, eeg, :, :] = np.abs(signal.cwt(np.squeeze(X[trial, :, eeg, :]),signal.morlet2,widths,w=w))\n\n    return X_cwt","metadata":{"id":"b7c6a147-544f-4c42-b964-e15e1bfcaf27","execution":{"iopub.status.busy":"2024-05-27T02:22:26.282590Z","iopub.execute_input":"2024-05-27T02:22:26.283012Z","iopub.status.idle":"2024-05-27T02:22:26.465662Z","shell.execute_reply.started":"2024-05-27T02:22:26.282978Z","shell.execute_reply":"2024-05-27T02:22:26.464313Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"os.getcwd()","metadata":{"id":"L4qidb2jv1CH","outputId":"b28b6054-3ec9-4bb4-dce7-1c4791b1e5c2","colab":{"base_uri":"https://localhost:8080/","height":35},"execution":{"iopub.status.busy":"2024-05-27T02:22:26.467220Z","iopub.execute_input":"2024-05-27T02:22:26.467586Z","iopub.status.idle":"2024-05-27T02:22:26.474796Z","shell.execute_reply.started":"2024-05-27T02:22:26.467555Z","shell.execute_reply":"2024-05-27T02:22:26.473740Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/cognitive-science-final-project'"},"metadata":{}}]},{"cell_type":"code","source":"def run():\n    # Define dataset parameters\n    dataset = 'BCI2a' # Options: 'BCI2a','HGD', 'CS2R'\n\n    if dataset == 'BCI2a':\n        in_samples = 1125\n        n_channels = 22\n        n_sub = 9\n        n_classes = 4\n        classes_labels = ['Left hand', 'Right hand','Foot','Tongue']\n        data_path = os.path.expanduser(root_datapath) + '/BCI Competition IV/BCI Competition IV-2a/BCI Competition IV 2a mat/'\n    elif dataset == 'HGD':\n        in_samples = 1125\n        n_channels = 44\n        n_sub = 14\n        n_classes = 4\n        classes_labels = ['Right Hand', 'Left Hand','Rest','Feet']\n        data_path = os.path.expanduser(root_datapath) + '/mne_data/MNE-schirrmeister2017-data/robintibor/high-gamma-dataset/raw/master/data/'\n    elif dataset == 'CS2R':\n        in_samples = 1125\n        # in_samples = 576\n        n_channels = 32\n        n_sub = 18\n        n_classes = 3\n        # classes_labels = ['Fingers', 'Wrist','Elbow','Rest']\n        classes_labels = ['Fingers', 'Wrist','Elbow']\n        # classes_labels = ['Fingers', 'Elbow']\n        data_path = os.path.expanduser(root_datapath) + '/CS2R MI EEG dataset/all/EDF - Cleaned - phase one (remove extra runs)/two sessions/'\n    else:\n        raise Exception(\"'{}' dataset is not supported yet!\".format(dataset))\n\n    # Create a folder to store the results of the experiment\n    results_path = os.getcwd() + \"/results\"\n    if not os.path.exists(results_path):\n      os.makedirs(results_path)   # Create a new directory if it does not exist\n\n    # Set dataset paramters\n    dataset_conf = { 'name': dataset, 'n_classes': n_classes, 'cl_labels': classes_labels,\n                    'n_sub': n_sub, 'n_channels': n_channels, 'in_samples': in_samples,\n                    'data_path': data_path, 'isStandard': True, 'LOSO': False}\n    # Set training hyperparamters\n    train_conf = { 'batch_size': 64, 'epochs': 100, 'patience': 10, 'lr': 0.001,'n_train': 1,\n                  'LearnCurves': True, 'from_logits': False, 'model':'ATCNet_CWT'}\n\n    # Train the model\n    train_model(dataset_conf, train_conf, results_path, cwt=True)\n\n    # Evaluate the model based on the weights saved in the '/results' folder\n    model = getModel(train_conf.get('model'), dataset_conf)\n    test(model, dataset_conf, results_path)","metadata":{"id":"105a3f77-4a7a-4eed-95de-83c0c78573d7","execution":{"iopub.status.busy":"2024-05-27T02:22:26.476199Z","iopub.execute_input":"2024-05-27T02:22:26.476564Z","iopub.status.idle":"2024-05-27T02:22:26.492581Z","shell.execute_reply.started":"2024-05-27T02:22:26.476536Z","shell.execute_reply":"2024-05-27T02:22:26.491068Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"run()","metadata":{"id":"6bef05f1","outputId":"c22a459f-e696-4dd5-b6ee-9d3d8e3e0aff","colab":{"base_uri":"https://localhost:8080/","height":468},"execution":{"iopub.status.busy":"2024-05-27T02:22:26.495090Z","iopub.execute_input":"2024-05-27T02:22:26.495597Z","iopub.status.idle":"2024-05-27T02:28:07.802579Z","shell.execute_reply.started":"2024-05-27T02:22:26.495555Z","shell.execute_reply":"2024-05-27T02:28:07.800966Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\nTraining on subject  1\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[12], line 46\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m train_conf \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m64\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m50\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.001\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_train\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     43\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearnCurves\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom_logits\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATCNet\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Evaluate the model based on the weights saved in the '/results' folder\u001b[39;00m\n\u001b[1;32m     49\u001b[0m model \u001b[38;5;241m=\u001b[39m getModel(train_conf\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m), dataset_conf)\n","Cell \u001b[0;32mIn[5], line 102\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(dataset_conf, train_conf, results_path, cwt)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[38;5;66;03m# model.summary()\u001b[39;00m\n\u001b[1;32m     93\u001b[0m             \u001b[38;5;66;03m# plot_model(model, to_file='plot_model.png', show_shapes=True, show_layer_names=True)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m             callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     96\u001b[0m                 ModelCheckpoint(filepath, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     97\u001b[0m                                 save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     98\u001b[0m                 ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),\n\u001b[1;32m     99\u001b[0m                 \u001b[38;5;66;03m# EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=patience)\u001b[39;00m\n\u001b[1;32m    100\u001b[0m             ]\n\u001b[0;32m--> 102\u001b[0m             history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_onehot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_onehot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m             \u001b[38;5;66;03m# Evaluate the performance of the trained model based on the validation data\u001b[39;00m\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;66;03m# Here we load the Trained weights from the file saved in the hard\u001b[39;00m\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;66;03m# disk, which should be the same as the weights of the current model.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m#             model.load_weights(filepath)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m             y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"id":"74e020b5"},"execution_count":null,"outputs":[]}]}